# -*- coding: utf-8 -*-
"""Gender Detect-95%.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fe2L-6-ZYaj10Audvi7hc1HwC40yqaDw
"""

import tensorflow as tf
from tensorflow import keras

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Import of keras model and hidden layers for our convolutional network
from keras.models import Sequential
from keras.layers.convolutional import Conv2D, MaxPooling2D
from keras.layers import Dense, Flatten, Dropout

#Image handling libraries
import numpy as np
import matplotlib.pyplot as plt
import cv2
import pandas as pd

#Sklearn libraries
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix

#Initialize a list of paths for images
imagepaths = []
path = '/content/drive/My Drive/Gender Detection/dataset/NewModel'

import os
for dirname, _, filenames in os.walk(path):
    for filename in filenames:
        path = os.path.join(dirname, filename)
        #print(os.path.join(dirname, filename))
        if path.endswith("jpg"):
            imagepaths.append(path)

print(len(imagepaths))

count = 0
for path in imagepaths[500:1000]:
  count+=1
  print(path, count)

def img_plot(img_path):
    img = cv2.imread(img_path)
    #convert to RGB space
    #img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    #check the shape of the image
    print("Shape of the image is ", img.shape)
    #Display the image
    plt.grid(False)
    plt.imshow(img)
    plt.xlabel("Width")
    plt.ylabel("Height")
    plt.title("Image " + img_path)

#### Creating Training Set and Labels ####
# X for image data
X = []
# y for the labels
y = []
count = 0

#Load the images into X by doing the necessary conversions and resizing of images
#Resizing is done to reduce the size of image to increase the speed of training
for path in imagepaths[:1940]:
    img = cv2.imread(path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = cv2.resize(img, (128,128))
    X.append(img)  
    #Getting the labels from the image path
    category = path.split("/")[7]
    #print(category)
    if category == "Man" or category == "Woman":
      y.append(category)
    count+=1
    print(f"{count} Images and labels appended")

#print(label)
#Turning X & y into numpy arrays
#data = pd.DataFrame(X,y)
X = np.array(X)
X = X.reshape(len(imagepaths[:1940]), 128, 128, 1)
y = np.array(y)

print("Images loaded: ", len(X))
print("Labels loaded: ", len(y))

print(y[0], imagepaths[0]) #To debug

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)

for i in range(500,1000):
  print(y[i])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=42)

# Create a CNN Sequential Model
model = Sequential()
model.add(Conv2D(32, (5,5), activation = 'relu', input_shape=(128,128,1)))
model.add(MaxPooling2D((2,2)))
model.add(Conv2D(64, (3, 3), activation='relu')) 
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu')) 
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu')) 
model.add(MaxPooling2D((2, 2)))

model.add(Flatten())

model.add(Dropout(0.5))
model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(2, activation='softmax'))

model.summary()

#Model configuration for training purpose
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

from keras.callbacks import ModelCheckpoint
from keras import callbacks

checkpoint = ModelCheckpoint('best_weight_04_08.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')
callbacks_list = [checkpoint]

model.fit(X_train, y_train, epochs=30, batch_size=64, verbose=1, 
         validation_data=(X_test, y_test), callbacks=callbacks_list)

model.load_weights('best_weight_04_08.h5')
tLoss, tAccuracy = model.evaluate(X_test, y_test)

print('Test accuracy: {:2.2f}%'.format(tAccuracy*100))
print('Test loss: {:2.2f}%'.format(tLoss*100))

test_path = '/content/drive/My Drive/Gender Detection/test/test_2'
test_image_paths = []
for dirname, _, filenames in os.walk(test_path):
    for filename in filenames:
        path = os.path.join(dirname, filename)
        #print(os.path.join(dirname, filename))
        if path.endswith("jpg"):
            test_image_paths.append(path)
print(len(test_image_paths))

X_test_new = []
for path in test_image_paths[:341]:
    img = cv2.imread(path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = cv2.resize(img, (128,128))
    X_test_new.append(img)

print(test_image_paths[])

X_test_new = np.array(X_test_new)
X_test_new = X_test_new.reshape(len(X_test_new), 128, 128, 1)

def validate_gestures(predictions_array, true_label_array, img_array):
  # Array for pretty printing and then figure size
  class_names = ["Man", "Woman"] 
  plt.figure(figsize=(15,5))
  
  for i in range(1, 10):
    # Just assigning variables
    prediction = predictions_array[i]
    true_label = true_label_array[i]
    img = img_array[i]
    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    
    # Plot in a good way
    plt.subplot(3,3,i)
    plt.grid(False)
    plt.xticks([])
    plt.yticks([])
    plt.imshow(img, cmap=plt.cm.binary)

    predicted_label = np.argmax(prediction) # Get index of the predicted label from prediction
    
    # Change color of title based on good prediction or not
    if predicted_label == true_label:
      color = 'blue'
    else:
      color = 'red'

    plt.xlabel("Predicted: {} {:2.0f}% (Actual: {})".format(class_names[predicted_label],
                                  100*np.max(prediction),
                                  class_names[true_label]),
                                  color=color)
  plt.show()

# Plot testing based on predictions and their actual values
#validate_gestures(prediction, y_test, X_test_new)
#Transform predictions into 1D array 
predict = model.predict(X_test_new)
y_pred = np.argmax(predict, axis=1)
validate_gestures(predict, y_pred, X_test_new)